 (cd "$(git rev-parse --show-toplevel)" && git apply --3way <<'EOF' 
diff --git a/README.md b/README.md
index eefd93faeb962162caf8d0353cfc34ff980e0a3b..098e854a22a552f574aa2217fc0d3a9c9741e62f 100644
--- a/README.md
+++ b/README.md
@@ -1 +1,145 @@
-# KAKAO_SemanticSegmentation_2025
+# KAKAO Semantic Segmentation 2025
+
+This repository provides the training and inference pipeline used for the KAKAO 2025 semantic segmentation task. It fine-tunes a DDRNet-based dual-resolution encoder on road-scene imagery and delivers end-to-end scripts covering training, evaluation, prediction export, and computational profiling.
+
+> ğŸ‡°ğŸ‡· **ìš”ì•½**: ì´ ì €ì¥ì†ŒëŠ” KAKAO 2025 ë„ë¡œ ì¥ë©´ ì‹œë§¨í‹± ì„¸ê·¸ë©˜í…Œì´ì…˜ ê³¼ì œë¥¼ ìœ„í•œ í•™ìŠµÂ·ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. DDRNet ê¸°ë°˜ì˜ ì´ì¤‘ í•´ìƒë„ ì¸ì½”ë”ë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ë©°, í•™ìŠµ/í‰ê°€/ì¶”ë¡ /í”„ë¡œíŒŒì¼ë§ ì „ì²´ ê³¼ì •ì„ ìˆ˜í–‰í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
+
+## Repository map
+
+| File | Purpose |
+| --- | --- |
+| `train.py` | Distributed training entrypoint. Builds the dataset, model, optimizer, and learning-rate schedule, then launches a multi-GPU training loop using PyTorch DDP. |
+| `train_sq.sh` | Convenience shell script that launches `train.py` with the hyperparameters used for the baseline submission. |
+| `DDRNet.py` | Implementation of DDRNet, including residual blocks, the dense attention pyramid pooling module (DAPPM), and segmentation heads. |
+| `functions.py` | Dataset utilities, data augmentations, loss functions, and learning-rate schedulers shared by training scripts. |
+| `prediction.py` | Loads trained weights and exports semantic labels and color-mapped overlays for the test set. |
+| `evaluation.py` | Computes pixel accuracy statistics (per-class IoU and mIoU) given predicted label maps and ground-truth annotations. |
+| `computation_time.py` | Measures FLOPs, parameter count, memory usage, and inference latency for DDRNet using THOP. |
+| `DDRNet23s_imagenet.pth` | Pre-trained ImageNet checkpoint used to initialize DDRNet. |
+
+| íŒŒì¼ | ìš©ë„ |
+| --- | --- |
+| `train.py` | PyTorch DDPë¥¼ í™œìš©í•´ ë©€í‹° GPU í•™ìŠµ ë£¨í”„ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë¶„ì‚° í•™ìŠµ ì§„ì…ì ì…ë‹ˆë‹¤. ë°ì´í„°ì…‹/ëª¨ë¸/ì˜µí‹°ë§ˆì´ì €/ëŸ¬ë‹ë ˆì´íŠ¸ ìŠ¤ì¼€ì¤„ì„ êµ¬ì„±í•©ë‹ˆë‹¤. |
+| `train_sq.sh` | ê¸°ì¤€ ì‹¤í—˜ì—ì„œ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ `train.py`ë¥¼ ì‹¤í–‰í•˜ëŠ” í¸ì˜ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤. |
+| `DDRNet.py` | ì”ì°¨ ë¸”ë¡, DAPPM, ì‹œë§¨í‹± í—¤ë“œë¥¼ í¬í•¨í•œ DDRNet êµ¬í˜„ì…ë‹ˆë‹¤. |
+| `functions.py` | ë°ì´í„°ì…‹ ìœ í‹¸, ë°ì´í„° ì¦ê°•, ì†ì‹¤ í•¨ìˆ˜, í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ë“±ì„ ì œê³µí•©ë‹ˆë‹¤. |
+| `prediction.py` | í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•œ ë¼ë²¨ ë§µê³¼ ì»¬ëŸ¬ ì˜¤ë²„ë ˆì´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. |
+| `evaluation.py` | ì˜ˆì¸¡ê³¼ ì •ë‹µì„ ë¹„êµí•´ í´ë˜ìŠ¤ë³„ IoUì™€ mIoUë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. |
+| `computation_time.py` | THOPì„ ì´ìš©í•´ FLOPs/íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ì¸¡ì •í•˜ê³ , ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ì¶”ë¡  ì§€ì—° ì‹œê°„ì„ ë¶„ì„í•©ë‹ˆë‹¤. |
+| `DDRNet23s_imagenet.pth` | DDRNet ì´ˆê¸°í™”ë¥¼ ìœ„í•œ ImageNet ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ì…ë‹ˆë‹¤. |
+
+## Data preparation
+
+The pipeline expects the dataset directory to contain:
+
+```
+<dataset_root>/
+  image/
+    train/<scene_id>/<frame>.png
+    val/<scene_id>/<frame>.png
+    test/<scene_id>/<frame>.png
+  labelmap/
+    train/<scene_id>/<frame>_gtFine_CategoryId.png
+    val/<scene_id>/<frame>_gtFine_CategoryId.png
+```
+
+* `train_sq.sh` assumes the dataset is unpacked into `./SemanticDataset_final`.
+* Test data lacks labels. Predicted labels are saved under `result/label/...` with the same relative paths as the inputs.
+
+> ğŸ‡°ğŸ‡· **ë°ì´í„° ì¤€ë¹„**
+>
+> * ë°ì´í„°ì…‹ì€ `image/{train,val,test}`ì™€ `labelmap/{train,val}` êµ¬ì¡°ë¥¼ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.
+> * `train_sq.sh`ëŠ” ë°ì´í„°ê°€ `./SemanticDataset_final` ê²½ë¡œì— ì••ì¶• í•´ì œë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
+> * í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ëŠ” ë¼ë²¨ì´ ì—†ìœ¼ë¯€ë¡œ, ì˜ˆì¸¡ ë¼ë²¨ì€ ì…ë ¥ê³¼ ë™ì¼í•œ ê²½ë¡œ êµ¬ì¡°ë¥¼ ê°–ëŠ” `result/label/...`ì— ì €ì¥ë©ë‹ˆë‹¤.
+
+## Data pipeline (`functions.py`)
+
+* `SegmentationDataset` searches under `image/<split>` and automatically maps each image file to the corresponding label file under `labelmap/`. The helper `_get_label_path` replaces the `_leftImg8bit` suffix with `_gtFine_CategoryId` so the correct annotation is found.
+* `SegmentationTransform` performs augmentation: random scaling, padding, random cropping to the configured `crop_size`, horizontal flipping, and ImageNet-style normalization. Labels are padded with `255` (ignore index) and converted to tensors.
+* `CrossEntropy` and `OhemCrossEntropy` wrap `nn.CrossEntropyLoss` to support auxiliary heads (DDRNet produces both a main and auxiliary prediction during training).
+* `WarmupPolyEpochLR` and `WarmupCosineAnnealingLR` provide warmup + decay schedules that adjust the optimizer learning rate after each epoch.
+* `load_state_dict` handles loading checkpoints regardless of whether they were saved from a DDP model (`module.` prefix) or a single-GPU model.
+
+> ğŸ‡°ğŸ‡· **ë°ì´í„° íŒŒì´í”„ë¼ì¸ ê°œìš”**
+>
+> * `SegmentationDataset`ì€ `image/<split>`ì˜ ì´ë¯¸ì§€ë¥¼ ìˆœíšŒí•˜ë©° íŒŒì¼ëª… ê·œì¹™ì„ ì´ìš©í•´ ë¼ë²¨ ê²½ë¡œë¥¼ ìë™ ë§¤í•‘í•©ë‹ˆë‹¤.
+> * `SegmentationTransform`ëŠ” ëœë¤ ìŠ¤ì¼€ì¼, íŒ¨ë”©, ëœë¤ í¬ë¡­, ì¢Œìš° ë°˜ì „, ì •ê·œí™”ë¥¼ ì ìš©í•´ í•™ìŠµ ë°ì´í„°ë¥¼ ì¦ê°•í•©ë‹ˆë‹¤. ë¼ë²¨ì€ `255`(ignore index)ë¡œ íŒ¨ë”©ë©ë‹ˆë‹¤.
+> * `CrossEntropy` / `OhemCrossEntropy`ëŠ” ë³´ì¡° í—¤ë“œë¥¼ í¬í•¨í•œ ì†ì‹¤ ê³„ì‚°ì„ ì§€ì›í•©ë‹ˆë‹¤.
+> * `WarmupPolyEpochLR`, `WarmupCosineAnnealingLR`ëŠ” ì›Œë°ì—… í›„ ë‹¤í•­/ì½”ì‚¬ì¸ ê°ì‡  í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ì„ ì œê³µí•©ë‹ˆë‹¤.
+> * `load_state_dict`ëŠ” DDP/ë‹¨ì¼ GPU ì²´í¬í¬ì¸íŠ¸ì˜ ì ‘ë‘ì‚¬ ì°¨ì´ë¥¼ ìë™ìœ¼ë¡œ ë³´ì •í•©ë‹ˆë‹¤.
+
+## Model architecture (`DDRNet.py`)
+
+DDRNet employs a dual-path encoder:
+
+1. **Low-resolution branch**: stacks residual `BasicBlock` layers with downsampling to extract high-level semantics. `compression3/4` project features for cross-path fusion.
+2. **High-resolution branch**: maintains spatial detail via parallel residual layers (`layer3_`, `layer4_`, `layer5_`). Down-sampling modules (`down3`, `down4`) pass detail back to the low-res branch.
+3. **DAPPM**: multi-scale pooling module that aggregates global context and merges it with the high-resolution stream.
+4. **Segmentation heads**: `segmenthead` upsamples logits back to the input resolution. During training an auxiliary head (`seghead_extra`) supervises intermediate features.
+
+The forward pass fuses features between both resolutions, applies DAPPM to the lowest-resolution tensor, and returns either `(main_logits, aux_logits)` in training mode or `main_logits` during inference.
+
+> ğŸ‡°ğŸ‡· **ëª¨ë¸ ì•„í‚¤í…ì²˜ ìš”ì•½**
+>
+> 1. ì €í•´ìƒë„ ë¶„ê¸°: ë‹¤ìš´ìƒ˜í”Œë§ëœ ì”ì°¨ ë¸”ë¡ìœ¼ë¡œ ê³ ìˆ˜ì¤€ ì˜ë¯¸ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ë©°, `compression3/4` ëª¨ë“ˆì´ ë¶„ê¸° ê°„ í”¼ì²˜ë¥¼ êµí™˜í•©ë‹ˆë‹¤.
+> 2. ê³ í•´ìƒë„ ë¶„ê¸°: `layer3_`, `layer4_`, `layer5_`ë¡œ ê³µê°„ ì •ë³´ë¥¼ ìœ ì§€í•˜ê³ , `down3/4` ëª¨ë“ˆì´ ì„¸ë¶€ ì •ë³´ë¥¼ ì €í•´ìƒë„ ë¶„ê¸°ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
+> 3. DAPPM: ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ í’€ë§ ì¶œë ¥ì„ ì—…ìƒ˜í”Œë§ í›„ ê²°í•©í•´ ì „ì—­ ë¬¸ë§¥ì„ ê°•í™”í•©ë‹ˆë‹¤.
+> 4. ì„¸ê·¸ë©˜í…Œì´ì…˜ í—¤ë“œ: ë³´ê°„ì„ í†µí•´ ì…ë ¥ í•´ìƒë„ë¡œ ë³µì›í•˜ë©°, í•™ìŠµ ì‹œ ë³´ì¡° í—¤ë“œ(`seghead_extra`)ë„ ì†ì‹¤ì— ì°¸ì—¬í•©ë‹ˆë‹¤.
+
+## Training loop (`train.py`)
+
+* Initializes NCCL distributed communication and sets the current CUDA device based on `LOCAL_RANK`.
+* Builds a `SegmentationDataset` and wraps it with a `DistributedSampler` for even sharding across GPUs. DataLoader workers are pinned for faster host-to-device transfers.
+* Constructs the DDRNet model and wraps it with `DistributedDataParallel` (`DDP`). Optionally loads ImageNet weights through `load_state_dict`.
+* Uses stochastic gradient descent with momentum and weight decay. The learning rate follows `WarmupPolyEpochLR`: a 5-epoch warmup followed by polynomial decay to 0.
+* Logs epoch losses and saves checkpoints under `result_dir`. The best checkpoint (lowest training loss) and periodic snapshots (`model_epoch{N}.pth`) are persisted by rank 0 only.
+* `train_sq.sh` launches the training script via `torchrun`, targeting 4 GPUs (IDs 0â€“3) with batch size 16, crop size 1024Ã—1024, scale jitter `[0.75, 1.25]`, and 20 epochs.
+
+> ğŸ‡°ğŸ‡· **í•™ìŠµ ë£¨í”„ ìš”ì•½**
+>
+> * NCCL ê¸°ë°˜ ë¶„ì‚° í†µì‹ ì„ ì´ˆê¸°í™”í•˜ê³  `LOCAL_RANK`ì— ë§ì¶° GPUë¥¼ í• ë‹¹í•©ë‹ˆë‹¤.
+> * `DistributedSampler`ë¡œ ë°ì´í„°ë¥¼ GPUë³„ë¡œ ê· ë“± ë¶„ë°°í•˜ë©°, ê³ ì •ëœ workerë¥¼ ì‚¬ìš©í•´ ë¡œë”© ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
+> * DDRNetì„ êµ¬ì„±í•´ `DistributedDataParallel`ë¡œ ë˜í•‘í•˜ê³ , í•„ìš” ì‹œ ImageNet ê°€ì¤‘ì¹˜ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.
+> * ëª¨ë©˜í…€/ê°€ì¤‘ ê°ì‡ ê°€ ìˆëŠ” SGDì™€ ì›Œë°ì—…+ë‹¤í•­ ê°ì‡  ìŠ¤ì¼€ì¤„(`WarmupPolyEpochLR`)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
+> * ì—í­ ì†ì‹¤ì„ ë¡œê¹…í•˜ê³  ì²´í¬í¬ì¸íŠ¸(`result_dir`)ë¥¼ ì €ì¥í•©ë‹ˆë‹¤. ìµœìƒìœ„ ëª¨ë¸ê³¼ ì£¼ê¸°ì  ìŠ¤ëƒ…ìƒ·ì€ 0ë²ˆ ë­í¬ë§Œ ê¸°ë¡í•©ë‹ˆë‹¤.
+> * `train_sq.sh`ëŠ” 4ê°œ GPU(0â€“3), ë°°ì¹˜ í¬ê¸° 16, í¬ë¡­ 1024Ã—1024, ìŠ¤ì¼€ì¼ ì§€í„° `[0.75, 1.25]`, ì´ 20 ì—í­ìœ¼ë¡œ `torchrun`ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
+
+## Inference (`prediction.py`)
+
+* `TestSegmentationDataset` iterates over test images and returns tensors without augmentations.
+* `load_model` wraps DDRNet in `DataParallel`, loads checkpoint weights (handling prefix mismatches), moves the model to the selected device, and switches to eval mode.
+* During prediction, each image is forwarded individually. Softmax+argmax produces the final class label per pixel.
+* `save_prediction` writes out the grayscale label map plus a Turbo colormap overlay for visual inspection. Output directory structure mirrors the input layout.
+
+> ğŸ‡°ğŸ‡· **ì¶”ë¡  íŒŒì´í”„ë¼ì¸**
+>
+> * `TestSegmentationDataset`ì€ ì¦ê°• ì—†ì´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
+> * `load_model`ì´ DDRNetì„ `DataParallel`ë¡œ ê°ì‹¼ ë’¤ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•˜ê³  í‰ê°€ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.
+> * ê° ì´ë¯¸ì§€ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì¶”ë¡ í•˜ê³  Softmax+Argmaxë¡œ í”½ì…€ë³„ í´ë˜ìŠ¤ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
+> * `save_prediction`ì€ íšŒìƒ‰ì¡° ë¼ë²¨ê³¼ Turbo ì»¬ëŸ¬ë§µ ì‹œê°í™”ë¥¼ ì…ë ¥ê³¼ ë™ì¼í•œ êµ¬ì¡°ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
+
+## Evaluation (`evaluation.py`)
+
+Given a directory of predicted label maps and the ground-truth label directory, `evaluate` aligns files by ID, ignores pixels with value 255, accumulates a confusion matrix, and reports class-wise IoU along with mean IoU (mIoU).
+
+> ğŸ‡°ğŸ‡· **í‰ê°€ ì§€í‘œ**
+>
+> ì˜ˆì¸¡ ë¼ë²¨ê³¼ ì •ë‹µ ë¼ë²¨ì„ ID ê¸°ì¤€ìœ¼ë¡œ ë§ì¶° 255(ignore)ë¥¼ ì œì™¸í•˜ê³  í˜¼ë™ í–‰ë ¬ì„ ëˆ„ì í•œ ë’¤ í´ë˜ìŠ¤ë³„ IoUì™€ mIoUë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
+
+## Computational profiling (`computation_time.py`)
+
+Measures several deployment metrics on a CUDA device:
+
+* Parameter count and FLOPs (via THOP).
+* Peak GPU memory consumption for a 1080Ã—1920 input.
+* Forward-pass latency statistics over 9 repeated groups of 200 iterations (after warmup), reporting both median latency and frames per second (FPS).
+
+These scripts together allow you to train, validate, test, and characterize the DDRNet segmentation model end-to-end for the KAKAO 2025 semantic segmentation challenge.
+
+> ğŸ‡°ğŸ‡· **ì„±ëŠ¥/ë³µì¡ë„ ë¶„ì„**
+>
+> * THOPìœ¼ë¡œ íŒŒë¼ë¯¸í„° ìˆ˜ì™€ FLOPsë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤.
+> * 1080Ã—1920 ì…ë ¥ ê¸°ì¤€ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
+> * 200íšŒ ë°˜ë³µì„ 9ê·¸ë£¹ìœ¼ë¡œ ìˆ˜í–‰í•œ ì¶”ë¡  ì§€ì—° ì‹œê°„ê³¼ FPSë¥¼ ì œê³µí•©ë‹ˆë‹¤.
+
+ì´ ë¬¸ì„œì— ì •ë¦¬ëœ ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ í™œìš©í•˜ë©´ DDRNet ê¸°ë°˜ ëª¨ë¸ì˜ í•™ìŠµë¶€í„° ì¶”ë¡ , í‰ê°€, ì„±ëŠ¥ ë¶„ì„ê¹Œì§€ í•œ ë²ˆì— ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
 
